{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef49187-d485-4279-be4c-758c77b9cbfe",
   "metadata": {},
   "source": [
    "# Kaggle Playground - Season 4 Episode \n",
    "## Binary Classification of Insurance Cross Selling\n",
    "\n",
    "Competion link - https://www.kaggle.com/competitions/playground-series-s4e8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c5446-7bde-481e-b86f-b56d636cb91f",
   "metadata": {},
   "source": [
    "### Steps\n",
    "- Import the necessary libraries, packages and modules\n",
    "- Read the datsets as data framers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39078c-9c75-4583-9df7-33ea4522274e",
   "metadata": {},
   "source": [
    "### Understand the problem\n",
    "\n",
    "- class is the target variable\n",
    "- It determines the class of a mushroom depending on the given variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfbb41e6-7354-42fc-9612-4c3138b7833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries, packages and modules\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import dtale    # Use of a web progrm to analysis the data deeply\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "# import statsmodels.api as sm\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import xgboost as xgb\n",
    "# import zipfile\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from optuna.samplers import TPESampler\n",
    "#from pandas_profiling import ProfileReport\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import (BaggingClassifier, RandomForestClassifier, AdaBoostClassifier,\n",
    "                              GradientBoostingClassifier, HistGradientBoostingClassifier)\n",
    "from sklearn.feature_selection import chi2, RFE, SelectKBest, SelectFromModel  \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer, matthews_corrcoef, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from skopt import BayesSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6bdb543-c63a-404d-a543-cccea02eb51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Test to see if TensorFlow can utilize the GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd0b9bd-a539-4585-8adb-9c0294737c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Train data load completed. Time elapsed: 4.09 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>e</td>\n",
       "      <td>8.80</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>4.51</td>\n",
       "      <td>x</td>\n",
       "      <td>h</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id class  cap-diameter cap-shape cap-surface cap-color  \\\n",
       "0   0     e          8.80         f           s         u   \n",
       "1   1     p          4.51         x           h         o   \n",
       "\n",
       "  does-bruise-or-bleed gill-attachment gill-spacing gill-color  ...  \\\n",
       "0                    f               a            c          w  ...   \n",
       "1                    f               a            c          n  ...   \n",
       "\n",
       "   stem-root  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0        NaN           NaN          w       NaN        NaN        f         f   \n",
       "1        NaN             y          o       NaN        NaN        t         z   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      a  \n",
       "1               NaN       d      w  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "logger.info(f\"Train data load completed. Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5eb23a83-e76a-4470-bf5f-323220940f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>...</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3116945</td>\n",
       "      <td>8.64</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>11.13</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>u</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3116946</td>\n",
       "      <td>6.90</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c</td>\n",
       "      <td>y</td>\n",
       "      <td>1.27</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "0  3116945          8.64         x         NaN         n                    t   \n",
       "1  3116946          6.90         o           t         o                    f   \n",
       "\n",
       "  gill-attachment gill-spacing gill-color  stem-height  ...  stem-root  \\\n",
       "0             NaN          NaN          w        11.13  ...          b   \n",
       "1             NaN            c          y         1.27  ...        NaN   \n",
       "\n",
       "  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0          NaN          w         u          w        t         g   \n",
       "1          NaN          n       NaN        NaN        f         f   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      a  \n",
       "1               NaN       d      a  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155c0975-bbdb-4768-9d61-f43a63f3f896",
   "metadata": {},
   "source": [
    "### Identify the target variable and features\n",
    "\n",
    "- class is the target variable\n",
    "- It determines the class of a mushroom depending on the given variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe796aa6-4445-4caa-b1ed-27058ee4fc02",
   "metadata": {},
   "source": [
    "### Remove duplicate rows\n",
    "\n",
    "- Checked the sum of duplicated rows in train and test datasets\n",
    "- No dupllicated rows in train dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06726f9b-0aa0-41e8-893d-8d6b226d879f",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    "- Checked the missing values in column\n",
    "- There are considerable amount of missing values in many columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "256fb363-6e4f-427d-9985-8626d461812f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3116945, 22)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b7d55b1-a95b-47a0-bdba-4e7d0574a75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2077964, 21)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22039987-da08-474d-a2d8-1fde55db683f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Train test split completed. Time elapsed: 6.54 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2419543</th>\n",
       "      <td>2419543</td>\n",
       "      <td>e</td>\n",
       "      <td>7.10</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910367</th>\n",
       "      <td>910367</td>\n",
       "      <td>p</td>\n",
       "      <td>7.11</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id class  cap-diameter cap-shape cap-surface cap-color  \\\n",
       "2419543  2419543     e          7.10         s           s         o   \n",
       "910367    910367     p          7.11         f         NaN         y   \n",
       "\n",
       "        does-bruise-or-bleed gill-attachment gill-spacing gill-color  ...  \\\n",
       "2419543                    f               d            d          b  ...   \n",
       "910367                     f               x            c          n  ...   \n",
       "\n",
       "         stem-root  stem-surface stem-color veil-type veil-color has-ring  \\\n",
       "2419543        NaN           NaN          w       NaN        NaN        f   \n",
       "910367         NaN           NaN          w       NaN        NaN        f   \n",
       "\n",
       "        ring-type spore-print-color habitat season  \n",
       "2419543         f               NaN       g      w  \n",
       "910367          f               NaN       d      a  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we have only one data set, spliting it into train and test (validation)\n",
    "\n",
    "train_df_split, validation_df = train_test_split(train_df, train_size = 0.75, random_state = 42, stratify = train_df['class'])\n",
    "logger.info(f\"Train test split completed. Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "train_df_split.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ced18-8b14-4857-b690-292a15d5c530",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "- Droping columns with more than 50% missing values\n",
    "- Using simple imputer\n",
    "- Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ae1569d-6023-41a2-9521-0f9780e4a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with extremely high missing values\n",
    "columns_to_drop = ['id', 'veil-type', 'spore-print-color', 'stem-root', 'veil-color', 'stem-surface']\n",
    "train_df_split.drop(columns=columns_to_drop, inplace=True)\n",
    "validation_df.drop(columns=columns_to_drop, inplace=True)\n",
    "test_df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35ff6836-6a55-4025-a7e4-b26e55cb208d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2419543</th>\n",
       "      <td>7.10</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>6.28</td>\n",
       "      <td>12.75</td>\n",
       "      <td>w</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910367</th>\n",
       "      <td>7.11</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>6.64</td>\n",
       "      <td>10.39</td>\n",
       "      <td>w</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "2419543          7.10         s           s         o                    f   \n",
       "910367           7.11         f         NaN         y                    f   \n",
       "\n",
       "        gill-attachment gill-spacing gill-color  stem-height  stem-width  \\\n",
       "2419543               d            d          b         6.28       12.75   \n",
       "910367                x            c          n         6.64       10.39   \n",
       "\n",
       "        stem-color has-ring ring-type habitat season  \n",
       "2419543          w        f         f       g      w  \n",
       "910367           w        f         f       d      a  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spliting dependent and independent valriable\n",
    "\n",
    "y_train = train_df_split['class']\n",
    "train_df_split = train_df_split.drop('class', axis = 1)\n",
    "\n",
    "y_val = validation_df['class']\n",
    "validation_df = validation_df.drop('class', axis = 1)\n",
    "\n",
    "train_df_split.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a572d25-9449-4679-a3fa-0bd06c7f695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Value is each categorical column :\n",
      "cap-shape 74\n",
      "Unique Value is each categorical column :\n",
      "cap-surface 83\n",
      "Unique Value is each categorical column :\n",
      "cap-color 78\n",
      "Unique Value is each categorical column :\n",
      "does-bruise-or-bleed 26\n",
      "Unique Value is each categorical column :\n",
      "gill-attachment 78\n",
      "Unique Value is each categorical column :\n",
      "gill-spacing 48\n",
      "Unique Value is each categorical column :\n",
      "gill-color 63\n",
      "Unique Value is each categorical column :\n",
      "stem-color 59\n",
      "Unique Value is each categorical column :\n",
      "has-ring 23\n",
      "Unique Value is each categorical column :\n",
      "ring-type 40\n",
      "Unique Value is each categorical column :\n",
      "habitat 52\n",
      "Unique Value is each categorical column :\n",
      "season 4\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical and categorical columns\n",
    "numerical_cols = train_df_split.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = train_df_split.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(\"Unique Value is each categorical column :\")\n",
    "    print(col, train_df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9b284d8-c741-4787-8e04-8db89cf00e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Missing values and categorical columns treatment completed. Time elapsed: 15.85 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Training Data Shape: (2337708, 15)\n",
      "Transformed Validation Data Shape: (779237, 15)\n",
      "Transformed Test Data Shape: (2077964, 15)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "# Define the imputer and scaler for numerical columns (median imputation and standard scaling)\n",
    "def preprocess_numerical_data(X, numerical_cols):\n",
    "    # Impute missing values with median\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_numerical_imputed = imputer.fit_transform(X[numerical_cols])\n",
    "    \n",
    "    # Scale the numerical data\n",
    "    scaler = StandardScaler()\n",
    "    X_numerical_scaled = scaler.fit_transform(X_numerical_imputed)\n",
    "    \n",
    "    return pd.DataFrame(X_numerical_scaled, columns=numerical_cols)\n",
    "\n",
    "# Define a function to apply LabelEncoder to each categorical column\n",
    "def encode_labels(df, columns):\n",
    "    df_encoded = df.copy()\n",
    "    le_dict = {}\n",
    "    for col in columns:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "        le_dict[col] = le\n",
    "    return df_encoded, le_dict\n",
    "\n",
    "# Define the function to transform categorical columns using LabelEncoder\n",
    "def encode_labels_transform(X, categorical_cols):\n",
    "    df = pd.DataFrame(X, columns=categorical_cols)\n",
    "    df_encoded, _ = encode_labels(df, categorical_cols)\n",
    "    return df_encoded.values\n",
    "\n",
    "# Define the function to preprocess the data\n",
    "def preprocess_data(X, numerical_cols, categorical_cols):\n",
    "    # Transform numerical columns\n",
    "    num_transformed = preprocess_numerical_data(X, numerical_cols)\n",
    "    \n",
    "    # Transform categorical columns\n",
    "    cat_transformed = encode_labels_transform(X, categorical_cols)\n",
    "    \n",
    "    # Combine transformed numerical and categorical columns\n",
    "    X_transformed = pd.concat([num_transformed, pd.DataFrame(cat_transformed, columns=categorical_cols)], axis=1)\n",
    "    return X_transformed\n",
    "\n",
    "# Assuming you have your train and test dataframes\n",
    "train_df_transformed = preprocess_data(train_df_split, numerical_cols, categorical_cols)\n",
    "validation_df_transformed = preprocess_data(validation_df, numerical_cols, categorical_cols)\n",
    "test_df_transformed = preprocess_data(test_df, numerical_cols, categorical_cols)\n",
    "\n",
    "print(\"Transformed Training Data Shape:\", train_df_transformed.shape)\n",
    "print(\"Transformed Validation Data Shape:\", validation_df_transformed.shape)\n",
    "print(\"Transformed Test Data Shape:\", test_df_transformed.shape)\n",
    "\n",
    "logger.info(f\"Missing values and categorical columns treatment completed. Time elapsed: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd8136a7-a097-4926-a64c-39910521f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the training labels\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "# Transform the labels for training and validation datasets\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4755d28-7161-4d0d-9fbe-520a91a0c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine feature names\n",
    "all_feature_names = numerical_cols.tolist() + categorical_cols.tolist()\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_df_transformed = pd.DataFrame(train_df_transformed, columns=all_feature_names)\n",
    "validation_df_transformed = pd.DataFrame(validation_df_transformed, columns=all_feature_names)\n",
    "test_df_transformed = pd.DataFrame(test_df_transformed, columns=all_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6dca119-07c8-4096-8169-c674a2836187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_memory_usage(df):\n",
    "    start_mem_usage = df.memory_usage().sum() / 1024 ** 2\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type.name in ['category', 'object']:\n",
    "            raise ValueError(f\"Column '{col}' is of type '{col_type.name}'\")\n",
    "\n",
    "        c_min = df[col].min()\n",
    "        c_max = df[col].max()\n",
    "        \n",
    "        if str(col_type)[:3] == 'int':\n",
    "            \n",
    "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "                \n",
    "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "                \n",
    "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "                \n",
    "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            \n",
    "            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            \n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem_usage = df.memory_usage().sum() / 1024**2\n",
    "    print(f'------ Memory usage before: {start_mem_usage:.2f} MB')\n",
    "    print(f'------ Memory usage after: {end_mem_usage:.2f} MB')\n",
    "    print(f'------ Reduced memory usage by {(100 * (start_mem_usage - end_mem_usage) / start_mem_usage):.1f}%')\n",
    "    print('**********************' * 5)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1842a1d3-764e-40ae-81c3-30848a4d27be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Memory usage before: 160.52 MB\n",
      "------ Memory usage after: 40.13 MB\n",
      "------ Reduced memory usage by 75.0%\n",
      "**************************************************************************************************************\n",
      "------ Memory usage before: 53.51 MB\n",
      "------ Memory usage after: 13.38 MB\n",
      "------ Reduced memory usage by 75.0%\n",
      "**************************************************************************************************************\n",
      "------ Memory usage before: 142.68 MB\n",
      "------ Memory usage after: 35.67 MB\n",
      "------ Reduced memory usage by 75.0%\n",
      "**************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "train_df_transformed = optimize_memory_usage(train_df_transformed)\n",
    "validation_df_transformed = optimize_memory_usage(validation_df_transformed)\n",
    "test_df_transformed = optimize_memory_usage(test_df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e5f8053-b3de-411f-a82c-a9434061302a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.169434</td>\n",
       "      <td>-0.025772</td>\n",
       "      <td>0.196899</td>\n",
       "      <td>53</td>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171509</td>\n",
       "      <td>0.107544</td>\n",
       "      <td>-0.094604</td>\n",
       "      <td>40</td>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  stem-height  stem-width  cap-shape  cap-surface  cap-color  \\\n",
       "0      0.169434    -0.025772    0.196899         53           62         57   \n",
       "1      0.171509     0.107544   -0.094604         40           73         69   \n",
       "\n",
       "   does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n",
       "0                     8               36            21          23   \n",
       "1                     8               61            18          40   \n",
       "\n",
       "   stem-color  has-ring  ring-type  habitat  season  \n",
       "0          42         4         13       21       3  \n",
       "1          42         4         13       18       0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_transformed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61fbba06-6be3-4b17-b615-a1843f32a9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.830078</td>\n",
       "      <td>0.042816</td>\n",
       "      <td>-1.059570</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.218262</td>\n",
       "      <td>-0.242676</td>\n",
       "      <td>-0.580078</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  stem-height  stem-width  cap-shape  cap-surface  cap-color  \\\n",
       "0     -0.830078     0.042816   -1.059570         36           17         21   \n",
       "1     -0.218262    -0.242676   -0.580078         36           29         21   \n",
       "\n",
       "   does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n",
       "0                     5               12            27          30   \n",
       "1                     5               31            27          20   \n",
       "\n",
       "   stem-color  has-ring  ring-type  habitat  season  \n",
       "0          34         3         11       11       2  \n",
       "1          26         3         11       11       3  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df_transformed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d1b353f-91b0-4f9c-979c-867ca0e7743e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.498047</td>\n",
       "      <td>1.772461</td>\n",
       "      <td>0.737305</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.126709</td>\n",
       "      <td>-1.880859</td>\n",
       "      <td>-0.049194</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>17</td>\n",
       "      <td>54</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  stem-height  stem-width  cap-shape  cap-surface  cap-color  \\\n",
       "0      0.498047     1.772461    0.737305         59           59         44   \n",
       "1      0.126709    -1.880859   -0.049194         50           53         45   \n",
       "\n",
       "   does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n",
       "0                    18               66            35          52   \n",
       "1                     5               66            17          54   \n",
       "\n",
       "   stem-color  has-ring  ring-type  habitat  season  \n",
       "0          51        17         15       16       0  \n",
       "1          38         6         14       16       0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_transformed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2db7c61d-18bf-4d1e-bc9e-d4c20b5a5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "def feature_selection(X_train, y_train, model):\n",
    "    if hasattr(model, 'coef_') or hasattr(model, 'feature_importances_'):\n",
    "        selector = SelectFromModel(model, threshold='mean')\n",
    "        selector.fit(X_train, y_train)\n",
    "        return selector.transform(X_train), selector.get_support()\n",
    "    else:\n",
    "        raise ValueError(\"Feature selection not supported for this model.\")\n",
    "\n",
    "def alternative_feature_selection(X_train, y_train):\n",
    "    selector = SelectKBest(score_func=f_classif, k='all')\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    return X_train_selected, selector.get_support()\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Ridge Classifier': RidgeClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Bagging Classifier': BaggingClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'SVC': SVC(),\n",
    " #  'KNN': KNeighborsClassifier(),\n",
    "    'XGBoost': xgb.XGBClassifier(tree_method='gpu_hist'),\n",
    "    'LightGBM': lgb.LGBMClassifier(device='gpu')\n",
    "}\n",
    "\n",
    "# Define parameter grids for RandomizedSearchCV\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'penalty': ['l2', 'l1', 'elasticnet', 'none'],\n",
    "        'C': np.logspace(-4, 4, 20),\n",
    "        'solver': ['lbfgs', 'liblinear', 'saga'],\n",
    "        'l1_ratio': np.linspace(0, 1, 10)  # Added this line\n",
    "    },\n",
    "    'Ridge Classifier': {\n",
    "        'alpha': uniform(0.1, 10),  # Regularization strength\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg'],\n",
    "        'fit_intercept': [True, False],\n",
    "        'max_iter': [100, 200, 300],\n",
    "        'tol': uniform(1e-4, 1e-2)\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'splitter': ['best', 'random'],\n",
    "        'max_depth': randint(3, 20),\n",
    "        'min_samples_split': uniform(0.01, 0.1),  # Random float between 0.01 and 0.1\n",
    "        'min_samples_leaf': uniform(0.01, 0.1),  # Random float between 0.01 and 0.1\n",
    "        'min_weight_fraction_leaf': uniform(0.0, 0.1),  # Random float between 0.0 and 0.1\n",
    "        'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "        'max_leaf_nodes': randint(10, 50),\n",
    "        'min_impurity_decrease': uniform(0.0, 0.1),\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    'Bagging Classifier': {\n",
    "        'estimator': [DecisionTreeClassifier(), None],  # Default is DecisionTreeClassifier\n",
    "        'n_estimators': randint(10, 100),\n",
    "        'max_samples': uniform(0.5, 1.0),  # Random float between 0.5 and 1.0\n",
    "        'max_features': uniform(0.5, 1.0),  # Random float between 0.5 and 1.0\n",
    "        'bootstrap': [True, False],\n",
    "        'bootstrap_features': [True, False],\n",
    "        'oob_score': [True, False],\n",
    "        'n_jobs': [None, -1],\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [None, randint(3, 20)],\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'min_samples_leaf': randint(1, 20),\n",
    "        'max_features': ['auto', 'sqrt', 'log2', uniform(0.5, 1.0)],\n",
    "        'bootstrap': [True, False],\n",
    "        'oob_score': [True, False],\n",
    "        'n_jobs': [None, -1],\n",
    "        'random_state': [42],\n",
    "        'verbose': [0, 1],\n",
    "        'warm_start': [True, False],\n",
    "        'class_weight': [None, 'balanced']\n",
    "    },\n",
    "    'AdaBoost Classifier': {\n",
    "        'base_estimator': [None, DecisionTreeClassifier(max_depth=1)],\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'learning_rate': uniform(0.01, 1.0),\n",
    "        'algorithm': ['SAMME', 'SAMME.R'],\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': randint(50, 300),\n",
    "        'learning_rate': uniform(0.01, 0.5),\n",
    "        'max_depth': randint(3, 10),\n",
    "        'min_samples_split': randint(2, 20),\n",
    "        'min_samples_leaf': randint(1, 20),\n",
    "        'max_features': ['sqrt', 'log2', None, uniform(0.1, 0.9)],\n",
    "        'subsample': uniform(0.5, 1.0),\n",
    "        'criterion': ['friedman_mse', 'squared_error', 'mae'],\n",
    "        'random_state': [42],\n",
    "        'verbose': [0, 1]\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': uniform(0.1, 10),\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'degree': randint(2, 5),\n",
    "        'gamma': ['scale', 'auto', uniform(0.001, 1)],\n",
    "        'coef0': uniform(0, 10),\n",
    "        'shrinking': [True, False],\n",
    "        'probability': [True, False],\n",
    "        'tol': uniform(1e-5, 1e-1),\n",
    "        'cache_size': uniform(50, 500),\n",
    "        'class_weight': [None, 'balanced'],\n",
    "        'verbose': [True, False],\n",
    "        'max_iter': [-1, 100, 200],\n",
    "        'decision_function_shape': ['ovr', 'ovo'],\n",
    "        'break_ties': [True, False],\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    'KNN': {\n",
    "        'n_neighbors': randint(1, 30),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "        'p': randint(1, 3),\n",
    "        'metric': ['minkowski', 'euclidean', 'manhattan', 'chebyshev', 'hamming'],\n",
    "        'leaf_size': randint(10, 50),\n",
    "        'n_jobs': [None, -1]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': randint(100, 300),\n",
    "        'max_depth': randint(3, 10),\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'subsample': uniform(0.5, 1.0),\n",
    "        'colsample_bytree': uniform(0.5, 1.0),\n",
    "        'gamma': uniform(0, 0.5),\n",
    "        'min_child_weight': randint(1, 10),\n",
    "        'reg_alpha': uniform(0, 1),\n",
    "        'reg_lambda': uniform(0, 1),\n",
    "        'scale_pos_weight': uniform(1, 10),\n",
    "        'max_delta_step': randint(0, 10),\n",
    "        'colsample_bylevel': uniform(0.5, 1.0),\n",
    "        'colsample_bynode': uniform(0.5, 1.0)\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'num_leaves': randint(20, 100),\n",
    "        'max_depth': randint(3, 15),\n",
    "        'learning_rate': uniform(0.01, 0.3),\n",
    "        'n_estimators': randint(100, 300),\n",
    "        'min_child_samples': randint(10, 100),\n",
    "        'min_split_gain': uniform(0, 0.5),\n",
    "        'subsample': uniform(0.5, 1.0),\n",
    "        'subsample_freq': randint(1, 10),\n",
    "        'colsample_bytree': uniform(0.5, 1.0),\n",
    "        'colsample_bylevel': uniform(0.5, 1.0),\n",
    "        'reg_alpha': uniform(0, 1),\n",
    "        'reg_lambda': uniform(0, 1),\n",
    "        'scale_pos_weight': uniform(1, 10)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Optuna objective function for XGBoost and LightGBM with regularization\n",
    "def objective(trial, model_name, model, X_train, y_train, X_val, y_val):\n",
    "    if model_name == 'XGBoost':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.3),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_uniform('gamma', 0, 0.5),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'reg_alpha': trial.suggest_uniform('reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_uniform('reg_lambda', 0, 1),\n",
    "            'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 1, 10),\n",
    "            'max_delta_step': trial.suggest_int('max_delta_step', 0, 10),\n",
    "            'colsample_bylevel': trial.suggest_uniform('colsample_bylevel', 0.5, 1.0),\n",
    "            'colsample_bynode': trial.suggest_uniform('colsample_bynode', 0.5, 1.0)\n",
    "        }\n",
    "    elif model_name == 'LightGBM':\n",
    "        params = {\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "            'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.3),\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "            'min_split_gain': trial.suggest_uniform('min_split_gain', 0, 0.5),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "            'subsample_freq': trial.suggest_int('subsample_freq', 1, 10),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "            'colsample_bylevel': trial.suggest_uniform('colsample_bylevel', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_uniform('reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_uniform('reg_lambda', 0, 1),\n",
    "            'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 1, 10)\n",
    "        }\n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    score = matthews_corrcoef(y_val, preds)\n",
    "    return score\n",
    "\n",
    "# Hyperparameter tuning using RandomizedSearchCV\n",
    "def tune_model(model_name, model, param_grid, X_train, y_train):\n",
    "    search = RandomizedSearchCV(\n",
    "        model, param_distributions=param_grid, n_iter=10, scoring='f1', cv=3, random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    print(f\"{model_name} Best Parameters (Random Search): {search.best_params_}\")  # Print best parameters\n",
    "    return search.best_estimator_, search.best_params_\n",
    "\n",
    "# Hyperparameter tuning using Optuna for XGBoost and LightGBM\n",
    "def optuna_tune_model(model_name, model, X_train, y_train, X_val, y_val):\n",
    "    study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "    study.optimize(lambda trial: objective(trial, model_name, model, X_train, y_train, X_val, y_val), n_trials=50)\n",
    "    print(f\"{model_name} Best Parameters (Optuna): {study.best_params}\")  # Print best parameters\n",
    "    return study.best_params\n",
    "\n",
    "# Train and evaluate models\n",
    "def evaluate_models(X_train, y_train, X_val, y_val):\n",
    "    best_models = {}\n",
    "    for name, model in models.items():\n",
    "        logger.info(f\"Evaluating {name}\")\n",
    "\n",
    "        # Feature Selection\n",
    "        if hasattr(model, 'coef_') or hasattr(model, 'feature_importances_'):\n",
    "            logger.info(f\"Performing feature selection for {name}\")\n",
    "            X_train_selected, support = feature_selection(X_train, y_train, model)\n",
    "            X_val_selected = X_val.iloc[:, support]\n",
    "        else:\n",
    "            logger.info(f\"Skipping feature selection for {name} due to lack of support\")\n",
    "            X_train_selected = X_train\n",
    "            X_val_selected = X_val\n",
    "\n",
    "        if name in ['XGBoost', 'LightGBM']:\n",
    "            # Perform Random Search\n",
    "            best_model, best_params_random = tune_model(name, model, param_grids[name], X_train_selected, y_train)\n",
    "            train_preds_random = best_model.predict(X_train_selected)\n",
    "            val_preds_random = best_model.predict(X_val_selected)\n",
    "            train_score_random = matthews_corrcoef(y_train, train_preds_random)\n",
    "            val_score_random = matthews_corrcoef(y_val, val_preds_random)\n",
    "            logger.info(f\"{name} (Random Search) - Train MCC Score: {train_score_random:.4f}\")\n",
    "            logger.info(f\"{name} (Random Search) - Validation MCC Score: {val_score_random:.4f}\")\n",
    "            \n",
    "            # Perform Bayesian Search (Optuna)\n",
    "            params_optuna = optuna_tune_model(name, model, X_train_selected, y_train, X_val_selected, y_val)\n",
    "            model.set_params(**params_optuna)\n",
    "            model.fit(X_train_selected, y_train)\n",
    "            train_preds_optuna = model.predict(X_train_selected)\n",
    "            val_preds_optuna = model.predict(X_val_selected)\n",
    "            train_score_optuna = matthews_corrcoef(y_train, train_preds_optuna)\n",
    "            val_score_optuna = matthews_corrcoef(y_val, val_preds_optuna)\n",
    "            logger.info(f\"{name} (Optuna) - Train MCC Score: {train_score_optuna:.4f}\")\n",
    "            logger.info(f\"{name} (Optuna) - Validation MCC Score: {val_score_optuna:.4f}\")\n",
    "            logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "            \n",
    "        else:\n",
    "            # Hyperparameter tuning using RandomizedSearchCV\n",
    "            best_model, best_params = tune_model(name, model, param_grids[name], X_train_selected, y_train)\n",
    "            model = best_model\n",
    "            train_preds = model.predict(X_train_selected)\n",
    "            val_preds = model.predict(X_val_selected)\n",
    "            train_score = matthews_corrcoef(y_train, train_preds)\n",
    "            val_score = matthews_corrcoef(y_val, val_preds)\n",
    "            logger.info(f\"{name} - Train MCC Score: {train_score:.4f}\")\n",
    "            logger.info(f\"{name} - Validation MCC Score: {val_score:.4f}\")\n",
    "            logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        best_models[name] = model\n",
    "\n",
    "    return best_models\n",
    "\n",
    "# Testing best models on the test set\n",
    "def test_best_models(best_models, X_train, y_train, X_val, y_val):\n",
    "    results = {}\n",
    "    for name, model in best_models.items():\n",
    "        # Training predictions and score\n",
    "        train_preds = model.predict(X_train)\n",
    "        train_score = matthews_corrcoef(y_train, train_preds)\n",
    "\n",
    "        # Validation predictions and score\n",
    "        val_preds = model.predict(X_val)\n",
    "        val_score = matthews_corrcoef(y_val, val_preds)\n",
    "\n",
    "        # Logging the scores\n",
    "        logger.info(f\"{name} - Train MCC Score: {train_score:.4f}\")\n",
    "        logger.info(f\"{name} - Validation MCC Score: {val_score:.4f}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        # Storing the results\n",
    "        results[name] = {\n",
    "            'train_score': train_score,\n",
    "            'val_score': val_score,\n",
    "            #'test_score': test_score\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d0fce02-416a-4a58-8076-79e1df0fc7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Evaluating Logistic Regression\n",
      "INFO:__main__:Skipping feature selection for Logistic Regression due to lack of support\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Best Parameters (Random Search): {'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.1111111111111111, 'C': 0.08858667904100823}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Logistic Regression - Train MCC Score: 0.2333\n",
      "INFO:__main__:Logistic Regression - Validation MCC Score: 0.1315\n",
      "INFO:__main__:Time elapsed: 455.78 seconds\n",
      "INFO:__main__:Evaluating Ridge Classifier\n",
      "INFO:__main__:Skipping feature selection for Ridge Classifier due to lack of support\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Classifier Best Parameters (Random Search): {'alpha': 3.845401188473625, 'fit_intercept': True, 'max_iter': 300, 'solver': 'cholesky', 'tol': 0.007896910002727693}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Ridge Classifier - Train MCC Score: 0.2337\n",
      "INFO:__main__:Ridge Classifier - Validation MCC Score: 0.1350\n",
      "INFO:__main__:Time elapsed: 482.59 seconds\n",
      "INFO:__main__:Evaluating Decision Tree\n",
      "INFO:__main__:Skipping feature selection for Decision Tree due to lack of support\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Best Parameters (Random Search): {'class_weight': None, 'criterion': 'entropy', 'max_depth': 17, 'max_features': 'log2', 'max_leaf_nodes': 17, 'min_impurity_decrease': 0.05986584841970366, 'min_samples_leaf': 0.025601864044243652, 'min_samples_split': 0.025599452033620268, 'min_weight_fraction_leaf': 0.005808361216819946, 'splitter': 'random'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Decision Tree - Train MCC Score: 0.0000\n",
      "INFO:__main__:Decision Tree - Validation MCC Score: 0.0000\n",
      "INFO:__main__:Time elapsed: 501.62 seconds\n",
      "INFO:__main__:Evaluating Bagging Classifier\n",
      "INFO:__main__:Skipping feature selection for Bagging Classifier due to lack of support\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_models \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_df_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel evaluation completed. Time elapsed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[28], line 256\u001b[0m, in \u001b[0;36mevaluate_models\u001b[1;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m    252\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime elapsed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Hyperparameter tuning using RandomizedSearchCV\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m     best_model, best_params \u001b[38;5;241m=\u001b[39m \u001b[43mtune_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grids\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m     model \u001b[38;5;241m=\u001b[39m best_model\n\u001b[0;32m    258\u001b[0m     train_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train_selected)\n",
      "Cell \u001b[1;32mIn[28], line 205\u001b[0m, in \u001b[0;36mtune_model\u001b[1;34m(model_name, model, param_grid, X_train, y_train)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(model_name, model, param_grid, X_train, y_train):\n\u001b[0;32m    202\u001b[0m     search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m    203\u001b[0m         model, param_distributions\u001b[38;5;241m=\u001b[39mparam_grid, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n\u001b[1;32m--> 205\u001b[0m     \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Best Parameters (Random Search): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Print best parameters\u001b[39;00m\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m search\u001b[38;5;241m.\u001b[39mbest_estimator_, search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1809\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1808\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1809\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1811\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1812\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1813\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    860\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:338\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# Convert data (X is required to be 2d and indexable)\u001b[39;00m\n\u001b[0;32m    330\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    331\u001b[0m     X,\n\u001b[0;32m    332\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    336\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    337\u001b[0m )\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:473\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    470\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39mn_more_estimators)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m seeds\n\u001b[1;32m--> 473\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_estimators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseeds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstarts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_n_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    492\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[0;32m    493\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:141\u001b[0m, in \u001b[0;36m_parallel_build_estimators\u001b[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose, check_input)\u001b[0m\n\u001b[0;32m    138\u001b[0m         curr_sample_weight[not_indices_mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    140\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[1;32m--> 141\u001b[0m     \u001b[43mestimator_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     X_ \u001b[38;5;241m=\u001b[39m X[indices][:, features] \u001b[38;5;28;01mif\u001b[39;00m requires_feature_indexing \u001b[38;5;28;01melse\u001b[39;00m X[indices]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "best_models = evaluate_models(train_df_transformed, y_train, validation_df_transformed, y_val)\n",
    "\n",
    "logger.info(f\"Model evaluation completed. Time elapsed: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c8866-3814-4340-b566-0ab6a5f28842",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748160c-ca2c-4c20-bffd-9738487ab4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_best_models(best_models, train_df_transformed, y_train, validation_df_transformed, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3878789b-0ccd-4b76-8001-7df92b6ef9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging\n",
    "logging.info(\"Starting cross-validation process\")\n",
    "logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Sort the models by their validation scores in descending order\n",
    "sorted_test_models = sorted(results.items(), key=lambda item: item[1]['val_score'], reverse=True)\n",
    "\n",
    "# Select the top 5 models based on validation scores\n",
    "five_best_models = {model_name: scores for model_name, scores in sorted_test_models[:5]}\n",
    "\n",
    "# Output the best five models based on validation scores\n",
    "for model_name, scores in five_best_models.items():\n",
    "    print(f\"Model: {model_name}, Validation MCC Score: {scores['val_score']}, Train MCC Score: {scores['train_score']}\")\n",
    "\n",
    "# The best_five_test_models dictionary now contains the top five models based on validation data performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c4e59-ac0f-4900-9197-e5b0a09c5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.info(\"Starting cross-validation process\")\n",
    "# logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# # Dictionary of the five best models based on the provided results\n",
    "# five_best_models = {\n",
    "#     'Bagging Classifier': BaggingClassifier(base_estimator=None, bootstrap=False,\n",
    "#                                             max_features=0.6039708314340944,\n",
    "#                                             max_samples=0.7838501639099957, n_estimators=72, n_jobs=-1,\n",
    "#                                             random_state=42),\n",
    "#     'Random Forest': RandomForestClassifier(class_weight='balanced', max_features='log2',\n",
    "#                                             min_samples_leaf=8, min_samples_split=8,\n",
    "#                                             n_estimators=171, oob_score=True, random_state=42,\n",
    "#                                             warm_start=True),\n",
    "#     'XGBoost': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "#                              colsample_bylevel=0.7324201991368923,\n",
    "#                              colsample_bynode=0.6984067959652569,\n",
    "#                              colsample_bytree=0.6585770133495129, device=None,\n",
    "#                              early_stopping_rounds=None, enable_categorical=False,\n",
    "#                              eval_metric=None, feature_types=None, gamma=0.3990553580730866,\n",
    "#                              grow_policy=None, importance_type=None,\n",
    "#                              interaction_constraints=None, learning_rate=0.23958788518583604,\n",
    "#                              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "#                              max_delta_step=5, max_depth=9, max_leaves=None,\n",
    "#                              min_child_weight=8, monotone_constraints=None,\n",
    "#                              multi_strategy=None, n_estimators=202, n_jobs=None,\n",
    "#                              num_parallel_tree=None, random_state=None),\n",
    "#     'LightGBM': LGBMClassifier(colsample_bytree=0.7085181455028883, device='gpu',\n",
    "#                                learning_rate=0.09554089088242068, max_depth=11,\n",
    "#                                min_child_samples=26, min_split_gain=0.18636874352935062,\n",
    "#                                n_estimators=233, num_leaves=117, reg_alpha=0.19897165336160308,\n",
    "#                                reg_lambda=0.13427322639962427,\n",
    "#                                scale_pos_weight=1.0239900845521561, subsample=0.595271788428719,\n",
    "#                                subsample_freq=8),\n",
    "#     'Gradient Boosting': GradientBoostingClassifier(criterion='squared_error',\n",
    "#                                                     learning_rate=0.1009124836035503, max_depth=7,\n",
    "#                                                     max_features='sqrt', min_samples_leaf=12,\n",
    "#                                                     min_samples_split=13, n_estimators=138,\n",
    "#                                                     random_state=42, subsample=0.645614570099021)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c42e21-4d3b-4b92-97bf-2b8cc8c4cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_sub = pd.read_csv('test.csv')\n",
    "test_df_sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de542ae-da1e-4476-8f06-2d5f5e300ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Train_ML function\n",
    "def Train_ML(Model, X, y, test_data):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    test_predictions = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X, y), 1):\n",
    "        # Handle indexing based on the type of X and y\n",
    "        if isinstance(X, pd.DataFrame) or isinstance(X, pd.Series):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        else:\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "        \n",
    "        if isinstance(y, pd.Series):\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        else:\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        Model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = Model.predict(X_train)\n",
    "        train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
    "        train_scores.append(train_mcc)\n",
    "\n",
    "        y_val_pred = Model.predict(X_val)\n",
    "        val_mcc = matthews_corrcoef(y_val, y_val_pred)\n",
    "        val_scores.append(val_mcc)\n",
    "        \n",
    "        y_test_pred_proba = Model.predict(test_data)\n",
    "        test_predictions.append(y_test_pred_proba)\n",
    "\n",
    "        print(f\"Fold {fold}: Train MCC = {train_mcc:.6f}, Validation MCC = {val_mcc:.6f}\")\n",
    "        logger.info(f\"Fold {fold}: Train MCC = {train_mcc:.6f}, Validation MCC = {val_mcc:.6f}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    mean_train_mcc = np.mean(train_scores)\n",
    "    mean_val_mcc = np.mean(val_scores)\n",
    "\n",
    "    print(f\"\\nMean Train MCC: {mean_train_mcc:.6f}\")\n",
    "    print(f\"Mean Validation MCC: {mean_val_mcc:.6f}\")\n",
    "    logger.info(f\"Mean Train MCC: {mean_train_mcc:.6f}, Mean Validation MCC: {mean_val_mcc:.6f}\")\n",
    "    logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    return Model, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97755317-72dd-4a73-a3f1-b50c22b76021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation, fit on the entire training data, and predict for each model\n",
    "for model_name, model in five_best_models.items():\n",
    "    try:\n",
    "        logger.info(f\"Starting model training and cross-validation for {model_name}\")\n",
    "        trained_model, test_preds = Train_ML(model, train_df_transformed, y_train, test_df_transformed)\n",
    "\n",
    "        # Averaging predictions across all folds\n",
    "        final_test_preds = np.mean(test_preds, axis=0)\n",
    "        final_test_preds_binary = (final_test_preds >= 0.5).astype(int)\n",
    "        \n",
    "        # Inverse transform the predictions to get the original class labels\n",
    "        predictions = label_encoder.inverse_transform(final_test_preds_binary)\n",
    "\n",
    "        # Log the prediction output\n",
    "        logger.info(f\"{model_name} - Test predictions done\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        # Output predictions to a CSV file\n",
    "        output_df = pd.DataFrame({'id': test_df_sub['id'], 'class': predictions})\n",
    "        output_df.to_csv(f'Submission_01A_Dropped_Simple_{model_name}.csv', index=False)\n",
    "        logger.info(f\"Generated output file for {model_name}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred with {model_name}: {e}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Print completion message\n",
    "print(\"Predictions for all five models have been saved to individual CSV files.\")\n",
    "logger.info(\"Predictions for all five models have been saved to individual CSV files.\")\n",
    "logger.info(f\"Total Time elapsed: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571508b-b088-4366-a96f-0841b59fd7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MCC as the scoring metric\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "\n",
    "# Perform cross-validation, fit on the entire training data, and predict for each model\n",
    "predictions = {}\n",
    "for model_name, model in five_best_models.items():\n",
    "    try:\n",
    "        logging.info(f\"Performing cross-validation for {model_name}\")\n",
    "        scores = cross_val_score(model, train_df_transformed, y_train, cv=5, scoring=mcc_scorer, n_jobs=-1)\n",
    "        logging.info(f\"{model_name} - CV Scores: {scores}\")\n",
    "        logging.info(f\"{model_name} - Mean CV Score: {np.mean(scores)}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        # Fit the model on the entire training data\n",
    "        model.fit(train_df_transformed, y_train)\n",
    "    \n",
    "        # Predict the output for test_df_transformed\n",
    "        preds = model.predict(test_df_transformed)\n",
    "\n",
    "        # Inverse transform the predictions to get the original class labels\n",
    "        predictions[model_name] = label_encoder.inverse_transform(preds)\n",
    "\n",
    "        # Log the prediction output\n",
    "        logging.info(f\"{model_name} - Test predictions done for {model_name}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        # Output predictions to a CSV file\n",
    "        output_df = pd.DataFrame({'id': test_df_sub['id'], 'class': predictions[model_name]})\n",
    "        output_df.to_csv(f'Submission_01A(2)_Dropped_Simple_{model_name}.csv', index=False)\n",
    "        print(output_df.head(2))\n",
    "        logger.info(f\"Generated output file - Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred with {model_name}: {e}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Print completion message\n",
    "print(\"Predictions for all five models have been saved to individual CSV files.\")\n",
    "print(\"Predictions for all five models have been saved to individual CSV files.\")\n",
    "logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a8f0c-a84f-4ee4-811a-64c9647e8718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
